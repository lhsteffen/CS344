{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 02\n",
    "This Jupyter Notebook creates a email spam filter and creates a Bayesian Network based on the image provided. This notebook also solves some of probabilities provided by hand as well as by the program.\n",
    "\n",
    "Author: Luke Steffen\n",
    "\n",
    "Version: Mar 12, 2020\n",
    "\n",
    "## Question 1: Spam Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words(list1, list2):\n",
    "    '''\n",
    "    Combines two lists into a single list\n",
    "    \n",
    "    This function takes two lists and combines them into a single, large list with no repeated words\n",
    "    \n",
    "    Parameters;\n",
    "    list1 (list): First list of words to be combined\n",
    "    list2 (list): Second list of words to be combined\n",
    "    \n",
    "    Returns:\n",
    "    words (list): A single, large list of words that contains no repeated words\n",
    "    '''\n",
    "    words = []\n",
    "    for word in list1:\n",
    "        if word not in words:\n",
    "            words.append(word)\n",
    "    for word in list2:\n",
    "        if word not in words:\n",
    "            words.append(word)\n",
    "    return words\n",
    "\n",
    "\n",
    "def get_lists_in_corpus(corpus):\n",
    "    '''\n",
    "    Gets the number of lists in a matrix\n",
    "    \n",
    "    This function takes a 2D matrix and counts how many lists are within the matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    corpus (list): A list of lists to be counted\n",
    "    \n",
    "    Returns:\n",
    "    count (int): The number of lists within the matrix\n",
    "    '''\n",
    "    count = 0\n",
    "    for l in corpus:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def flatten_list(corpus):\n",
    "    '''\n",
    "    Takes a matrix and returns a list\n",
    "    \n",
    "    This function takes a 2D matrix and returns a single list containing all values within the original 2D matrix\n",
    "    \n",
    "    Parameters:\n",
    "    corpus (list): A 2D matrix of words\n",
    "    \n",
    "    Returns:\n",
    "    flattened (list): A list containing all values within the original matrix\n",
    "    '''\n",
    "    flattened = []\n",
    "    for email in corpus:\n",
    "        for word in email:\n",
    "            flattened.append(word)\n",
    "    return flattened\n",
    "\n",
    "\n",
    "def get_word_count(corpus):\n",
    "    '''\n",
    "    Counts how many words are in a list\n",
    "    \n",
    "    This function counts the number of times a word appears in a list. The function returns a dictionary\n",
    "    containing all of the words and a count of them.\n",
    "    \n",
    "    Parameters:\n",
    "    corpus (list): A list of words\n",
    "    \n",
    "    Returns:\n",
    "    word_count (dict): A dictionary of words with the number of times they appeared in the input list\n",
    "    '''\n",
    "    word_count = {}\n",
    "    for word in corpus:\n",
    "        count = 0\n",
    "        for check in corpus:\n",
    "            if check == word:\n",
    "                count += 1\n",
    "        word_count[word] = count\n",
    "    return word_count\n",
    "\n",
    "\n",
    "def get_word_spam_probability(word, good, bad, nbad, ngood):\n",
    "    '''\n",
    "    Calculate a word's spam probability\n",
    "    \n",
    "    This function calculates the probability of a word being associated with a spam email. The higher\n",
    "    the probability, the more likely that word is to appear in spam emails\n",
    "    \n",
    "    Parameters:\n",
    "    word (string): Any word that will be checked for its probability to be in spam emails\n",
    "    good (dict): A dictionary of word counts for a corpus of good/HAM emails\n",
    "    bad (dict): A dictionary of word counts for a corpus of bad/SPAM emails\n",
    "    nbad (int): The number of bad emails used to create the bad dictionary\n",
    "    ngood (int): The number of good emails used to create the good dictionary\n",
    "    \n",
    "    Returns:\n",
    "    probability or 0 (int): The probability of a word appearing in a spam email\n",
    "    '''\n",
    "    if word in good.keys():\n",
    "        good_value = 2 * good[word]\n",
    "    else:\n",
    "        good_value = 0\n",
    "    if word in bad.keys():\n",
    "        bad_value = bad[word]\n",
    "    else:\n",
    "        bad_value = 0\n",
    "    if good_value + bad_value > 1:\n",
    "        return max(0.01, min(0.99, min(1.0, bad_value/nbad) / (min(1.0, good_value/ngood) + min(1.0, bad_value/nbad))))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def is_email_spam(email, probabilities):\n",
    "    '''\n",
    "    Returns the probability of an email being spam\n",
    "    \n",
    "    This function takes an email and probabilities of words being in spam email and returns\n",
    "    the product of the word probabilities. This answer acts as a total probability for the \n",
    "    specified email being spam\n",
    "    \n",
    "    Parameters:\n",
    "    email (list): A list of words, numbers, html tags that compose an email\n",
    "    probabilities (dict): A dictionary of words and their probabilities of being in spam emails\n",
    "    \n",
    "    Returns:\n",
    "    product (float): The probability of the input email being spam \n",
    "    '''\n",
    "    product = 1\n",
    "    complement = 1\n",
    "    for w in email:\n",
    "        product = product * probabilities[w]\n",
    "        complement = complement * (1 - probabilities[w])\n",
    "    return product / (product + complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Probabilities\n",
      "do: 0.3333333333333333\n",
      "i: 0.01\n",
      "like: 0.3333333333333333\n",
      "green: 0.01\n",
      "eggs: 0.01\n",
      "and: 0.01\n",
      "ham: 0.01\n",
      "I: 0.99\n",
      "am: 0.99\n",
      "spam: 0.99\n",
      "not: 0\n",
      "that: 0\n",
      "spamiam: 0\n",
      "\n",
      "\n",
      "Spam email number 1:  ['I', 'am', 'spam', 'spam', 'I', 'am']\n",
      "Spam email number 2:  ['I', 'do', 'not', 'like', 'that', 'spamiam']\n",
      "\n",
      "\n",
      "Ham email number 1:  ['do', 'i', 'like', 'green', 'eggs', 'and', 'ham']\n",
      "Ham email number 2:  ['i', 'do']\n",
      "\n",
      "\n",
      "Spam probability for spam email 1 is: 0.9999999999989378\n",
      "Spam probability for spam email 2 is: 0.0\n",
      "\n",
      "\n",
      "Spam probability for ham email 1 is: 2.6288392819642677e-11\n",
      "Spam probability for ham email 2 is: 0.005025125628140704\n"
     ]
    }
   ],
   "source": [
    "# Spam corpus and Ham corpus\n",
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "\n",
    "# Creation of word counts, email counts, and all words\n",
    "ham_count = get_word_count(flatten_list(ham_corpus))\n",
    "spam_count = get_word_count(flatten_list(spam_corpus))\n",
    "ham_emails = get_lists_in_corpus(ham_corpus)\n",
    "spam_emails = get_lists_in_corpus(spam_corpus)\n",
    "all_words = get_all_words(flatten_list(ham_corpus), flatten_list(spam_corpus))\n",
    "\n",
    "# Calculation of word probabilities for all words in both corpuses\n",
    "probabilities = {}\n",
    "for word in all_words:\n",
    "    probabilities[word] = get_word_spam_probability(word, ham_count, spam_count, 2, 2)\n",
    "\n",
    "# Print the probabilities of each word being spam\n",
    "print(\"Word Probabilities\")\n",
    "for word in probabilities.keys():\n",
    "    print(\"{}: {}\".format(word, probabilities[word]))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Display of all spam and ham emails and their assigned number\n",
    "email_number = 0\n",
    "for email in spam_corpus:\n",
    "    email_number += 1\n",
    "    print(\"Spam email number \" + str(email_number) + \": \", end=\" \")\n",
    "    print(email)\n",
    "\n",
    "print(\"\\n\")\n",
    "email_number = 0\n",
    "for email in ham_corpus:\n",
    "    email_number += 1\n",
    "    print(\"Ham email number \" + str(email_number) + \": \", end=\" \")\n",
    "    print(email)\n",
    "\n",
    "print(\"\\n\")\n",
    "# Display of spam probability for all spam and ham emails, with their assigned number\n",
    "email_number = 0\n",
    "for email in spam_corpus:\n",
    "    email_number += 1\n",
    "    print(\"Spam probability for spam email \" + str(email_number) + \" is: \" + str(is_email_spam(email, probabilities)))\n",
    "\n",
    "print(\"\\n\")\n",
    "email_number = 0\n",
    "for email in ham_corpus:\n",
    "    email_number += 1\n",
    "    print(\"Spam probability for ham email \" + str(email_number) + \" is: \" + str(is_email_spam(email, probabilities)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Bayesian approach to spam because it does not use a large, unweildy joint distribution table. This method calculates probabilities of words using minimal amounts of information, only needing a word count, number of emails, and a ham or spam corpus. From this, the code is sort of able to create a Bayesian Network, where Spam is a parent node and all of the words are children nodes. Because the code is setup this way, there is less space used and probabilities can still be calculated quickly. Because of these factors, this approach can be considered a Bayesian approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Bayesian Network\n",
    "![title](figure14_12.png)\n",
    "\n",
    "Implementation of the Bayesian Network in figure a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'probability'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-633962513b0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumeration_ask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melimination_ask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgibbs_ask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'probability'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from probability import BayesNet, enumeration_ask, elimination_ask, gibbs_ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BayesNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dccf4387be01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Creation of Bayesian Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m cloudy = BayesNet([\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'Cloudy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'Sprinkler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cloudy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BayesNet' is not defined"
     ]
    }
   ],
   "source": [
    "# Utility variables\n",
    "T = True\n",
    "F = False\n",
    "\n",
    "# Creation of Bayesian Network\n",
    "cloudy = BayesNet([\n",
    "    ('Cloudy', '', 0.5),\n",
    "    ('Sprinkler', 'Cloudy', {T: 0.1, F: 0.5}),\n",
    "    ('Rain', 'Cloudy', {T: 0.8, F: 0.2}),\n",
    "    ('WetGrass', 'Rain Sprinkler', {(T, T): 0.99, (T, F): 0.9, (F, T): 0.9, (F, F): 0.0})\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Cloudy)\n",
      "False: 0.5, True: 0.5\n",
      "\n",
      "P(Sprinkler | Cloudy)\n",
      "False: 0.9, True: 0.1\n",
      "\n",
      "P(Cloudy | Sprinkler ^ Not Rain)\n",
      "False: 0.952, True: 0.0476\n",
      "\n",
      "P(WetGrass | Cloudy ^ Sprinkler ^ Rain)\n",
      "False: 0.01, True: 0.99\n",
      "\n",
      "P(Cloudy | Not WetGrass)\n",
      "False: 0.639, True: 0.361\n"
     ]
    }
   ],
   "source": [
    "# Compute P(Cloudy)\n",
    "print(\"P(Cloudy)\")\n",
    "print(enumeration_ask('Cloudy', dict(), cloudy).show_approx())\n",
    "\n",
    "# Compute P(Sprinkler | Cloudy)\n",
    "print(\"\\nP(Sprinkler | Cloudy)\")\n",
    "print(enumeration_ask('Sprinkler', dict(Cloudy=T), cloudy).show_approx())\n",
    "\n",
    "# Compute P(Cloudy | Sprinkler ^ Not Rain)\n",
    "print(\"\\nP(Cloudy | Sprinkler ^ Not Rain)\")\n",
    "print(enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=F), cloudy).show_approx())\n",
    "\n",
    "# Compute P(WetGrass | Cloudy ^ Sprinkler ^ Rain)\n",
    "print(\"\\nP(WetGrass | Cloudy ^ Sprinkler ^ Rain)\")\n",
    "print(enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), cloudy).show_approx())\n",
    "\n",
    "# Compute P(Cloudy | Not WetGrass)\n",
    "print(\"\\nP(Cloudy | Not WetGrass)\")\n",
    "print(enumeration_ask('Cloudy', dict(WetGrass=F), cloudy).show_approx())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.\n",
    "\n",
    "    +---------------------------------------------------------------------------------------------------------+\n",
    "    |                       Cloudy 0.5                  |                       ¬Cloudy 0.5                   |\n",
    "    +---------------------------------------------------|--------------------------|--------------------------+\n",
    "    |         Spinkler 0.1    |        ¬Sprinkler 0.9   |         Sprinkler 0.5    |   ¬Sprinkler 0.5         |\n",
    "    +------------|------------|------------|------------|-------------|------------|------------|-------------+\n",
    "    |   Rain 0.8 |   Rain 0.2 |   Rain 0.8 |  ¬Rain 0.2 |    Rain 0.2 |  ¬Rain 0.8 |   Rain 0.2 |  ¬Rain 0.8  |\n",
    "    +-----|------|-----|------|-----|------|-----|------|------|------|-----|------|-----|------|-----|-------+\n",
    "    |Grass|¬Grass|Grass|¬Grass|Grass|¬Grass|Grass|¬Grass| Grass|¬Grass|Grass|¬Grass|Grass|¬Grass|Grass|¬Grass |\n",
    "    +-----|------|-----|------|-----|------|-----|------|------|------|-----|------|-----|------|-----|-------+\n",
    "    |0.99 | 0.01 | 0.9 | 0.1  | 0.9 | 0.1  | 0.0 | 1.0  | 0.99 | 0.01 | 0.9 | 0.1  | 0.9 | 0.1  | 0.0 | 1.0   |\n",
    "    +---------------------------------------------------------------------------------------------------------+\n",
    "    \n",
    "From this full joint probability table, we can determine that WetGrass and Cloudy are independent variables. We\n",
    "know this because the probabilities do not change between Cloudy and ¬Cloudy. We can also tell that Sprinkler and\n",
    "rain are independent from each other because Rain does not change between Sprinkler and ¬Sprinkler. However, we\n",
    "know Rain and Sprinkler are dependent on Cloudy because the probabilities change between Cloudy and ¬Cloudy.\n",
    "\n",
    "c. Based on the representation of the Bayesian Network shown above, there are 2 pairs of independent variables, sprinkler and rain, and Cloudy and WetGrass. We know this because a connecting line between nodes means there is a dependence. Since there are no lines between Sprinkler and Rain, these two variables are independent. The same rule applies to Cloudy and WetGrass.\n",
    "   \n",
    "d. \n",
    "\n",
    "   P(Cloudy) = <0.5, 0.5> (Given)\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "   P(Sprinkler | Cloudy) = <0.1, 0.9> (Given)\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "   P(Cloudy | Sprinkler ^ Not Rain) = alpha * (P(Sprinkler ^ Not Rain) * P(Cloudy))\n",
    "   \n",
    "   P(Cloudy | Sprinkler ^ Not Rain) = alpha * (0.1 * 0.8 * 0.5)\n",
    "   \n",
    "   P(Cloudy | Sprinkler ^ Not Rain) = alpha * 0.04\n",
    "   \n",
    "   P(Cloudy | Sprinkler ^ Not Rain) = <0.0476, 0.952>\n",
    " \n",
    "------------------------------------------------------------------------------------------------------------------\n",
    "  \n",
    "   P(WetGrass | Cloudy ^ Sprinkler ^ Rain) = P(WetGrass | Sprinkler ^ Rain)\n",
    "   \n",
    "   P(WetGrass | Cloudy ^ Sprinkler ^ Rain) = <0.99, 0.01> (Given)\n",
    "   \n",
    "   This is because Cloudy has no effect on WetGrass, only Sprinkler and Rain\n",
    "   have an effect. This is because Cloudy and WetGrass are independent.\n",
    "   \n",
    "------------------------------------------------------------------------------------------------------------------\n",
    "   \n",
    "   P(Cloudy | Not WetGrass)\n",
    "   \n",
    "   \n",
    "   This portion shows a visual representation of the binary tree used to solve this\n",
    "   problem. The tree is split into two subsections, the probability of it being cloudy\n",
    "   and the probability of it not being cloudy. The numbers are multiplied down to each\n",
    "   leaf, then summed to find the total probability.\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "                                                  P(C)\n",
    "                                ___________________|______________________\n",
    "                               /                                          \\\n",
    "                              /                                            \\\n",
    "                             /                                              \\\n",
    "                            /                                                \\\n",
    "                           /                                                  \\\n",
    "                    P(S | C) = 0.1                                    P(¬S | C) = 0.9\n",
    "                   /             \\                                   /                \\\n",
    "                  /               \\                                 /                  \\\n",
    "                 /                 \\                               /                    \\\n",
    "                /                   \\                             /                      \\\n",
    "               /                     \\                           /                        \\\n",
    "              /                       \\                         /                          \\\n",
    "      P(R | S, C) = 0.8        P(¬R | S, C) = 0.2        P(R | ¬S, C) = 0.8        P(¬R | ¬S, C) = 0.2\n",
    "             |                        |                         |                          |\n",
    "             |                        |                         |                          |\n",
    "    P(¬W | R, S, C) = 0.01    P(¬W | ¬R, S, C) = 0.1    P(¬W | R, ¬S, C) = 0.1    P(¬W | ¬R, ¬S, C) = 1.0\n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   P(C) = (0.1 * 0.8 * 0.01) + (0.1 * 0.2 * 0.1) + (0.9 * 0.8 * 0.1) + (0.9 * 0.2 * 1.0) = 0.2548 * alpha\n",
    "   \n",
    "   \n",
    "------------------------------------------------------------------------------------------------------------------   \n",
    "   \n",
    "   \n",
    "   \n",
    "                                                P(¬C)\n",
    "                                ___________________|______________________\n",
    "                               /                                          \\\n",
    "                              /                                            \\\n",
    "                             /                                              \\\n",
    "                            /                                                \\\n",
    "                           /                                                  \\\n",
    "                    P(S | ¬C) = 0.5                                   P(¬S | ¬C) = 0.5\n",
    "                   /             \\                                   /                \\\n",
    "                  /               \\                                 /                  \\\n",
    "                 /                 \\                               /                    \\\n",
    "                /                   \\                             /                      \\\n",
    "               /                     \\                           /                        \\\n",
    "              /                       \\                         /                          \\\n",
    "      P(R | S, ¬C) = 0.2       P(¬R | S, ¬C) = 0.8        P(R | ¬S, ¬C) = 0.2        P(¬R | ¬S, ¬C) = 0.8\n",
    "             |                        |                         |                          |\n",
    "             |                        |                         |                          |\n",
    "    P(¬W | R, S, ¬C) = 0.01   P(¬W | ¬R, S, ¬C) = 0.1    P(¬W | R, ¬S, ¬C) = 0.1    P(¬W | ¬R, ¬S, ¬C) = 1.0\n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   P(¬C) = (0.5 * 0.2 * 0.01) + (0.5 * 0.8 * 0.1) + (0.5 * 0.2 * 0.1) + (0.5 * 0.8 * 1.0) = 0.451 * alpha\n",
    "   \n",
    "   \n",
    "   P(Cloudy | ¬WetGrass) = alpha <0.2548, 0.451>\n",
    "   \n",
    "   alpha = 1 / (0.2548 + 0.451) = 1.4168\n",
    "   \n",
    "   P(Cloudy | ¬WetGrass) = <0.361, 0.639>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
