{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 03\n",
    "\n",
    "This Jupyter notebook calculates information gain of the restaurant example, examines the XOR network, and uses Keras to create a model for the Boston Housing dataset.\n",
    "\n",
    "Author: Luke Steffen (lhs3)\n",
    "\n",
    "Version: 04/06/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Information Gain of price\n",
    "![title](restaurant_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Information Gain = Gain(A) = B(p/(p+n)) - Remainder(A)**\n",
    "\n",
    "B(p/(p+n)) = 6 / 12 = 0.5 -> 1 bit\n",
    "\n",
    "B(q) = -(q * log2(q) + (1 - q) * log2(1 - q))\n",
    "\n",
    "Remainder(A) = Sum[(pk + nk)/(p+n) * B(pk/(pk + nk))]\n",
    "\n",
    "Price -> 3 choices for attribute\n",
    "\n",
    "\\$ -> 7 occurrences\n",
    "\n",
    "\\$$ -> 2 occurrences\n",
    "\n",
    "\\$$$ -> 3 occurrences\n",
    "\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "\\$ -> 3 positive occurrences & 4 negative occurrences\n",
    "\n",
    "\\$$ -> 2 positive occurrences & 0 negative occurrences\n",
    "\n",
    "\\$$$ -> 1 positive occurrence & 2 negative occurrences\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "\n",
    "**Sum[(pk + nk)/(p+n) * B(pk/(pk + nk))]**\n",
    "\n",
    "\\$ -> (3 + 4) / (6 + 6) * B(3 / (3 + 4)) = 0.5747164127\n",
    "\n",
    "    B(3/7) = 0.985228136\n",
    "    \n",
    "\\$$ -> (2 + 0) / (6 + 6) * B(2 / (2 + 0)) = 0\n",
    "\n",
    "    B(1) = 0\n",
    "    \n",
    "\\$$$ -> (1 + 2) / (6 + 6) * B(1 / (1 + 2)) = 0.2295739585\n",
    "\n",
    "    B(1/3) = 0.9182958341\n",
    "    \n",
    "Sum[(pk + nk)/(p+n) * B(pk/(pk + nk))] = 0.5747164127 + 0 + 0.2295739585 = 0.804\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "\n",
    "Gain(Price) = 1 - 0.804 = 0.196 bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information gain from making the root of the tree price results in\n",
    "0.196 bits gained. The information gained from price is higher than the information gained from type, which is 0 bits. However, it is not as much gain as patrons, which had a gain of 0.541 bits. Because partons has a higher information gain, it would be a better option to make patrons the root of the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. XOR Network Simplification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not possible to simplify the network beyond the network created in class. The network created in class is below.\n",
    "\n",
    "\n",
    "                        input1  input2                               input1   input2\n",
    "               (weight1)   \\      /  (weight2)               (weight1)   \\     /   (weight2)\n",
    "                            \\    /                                        \\   /\n",
    "                           AND Node   <- bias1                           OR Node   <- bias1\n",
    "                               |                                            |\n",
    "                               |                                            |\n",
    "                                \\                                          /\n",
    "                                 \\                                        /\n",
    "                                  \\                                      /\n",
    "                                   \\                                    /\n",
    "                                    \\                                  /\n",
    "                                     \\                                /\n",
    "                                      \\                              /\n",
    "                                       \\                            /\n",
    "                                        \\ weight3          weight3 /\n",
    "                                         -------            -------\n",
    "                                                \\          /\n",
    "                                         bias2 -> Neuron 3\n",
    "                                                     |\n",
    "                                                     |\n",
    "                                                     |\n",
    "                                                   Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why this cannot be further simplified is because of the nature of the XOR problem. If we were to use only one layer, we would be using perceptrons instead of a neural network. Perceptrons are only able to solve problems that are linearly separable. A lineraly separable problem is one that, when graphed, a linear line can be drawn which separates positive answers from negative answers. XOR is not a linearly separable problem and this can be shown if the problem is graphed, which would look something like the below graph.\n",
    "\n",
    "                   1 o            *\n",
    "                     |\n",
    "                     |\n",
    "                     |\n",
    "                     |\n",
    "                     |\n",
    "                     *------------o\n",
    "                     0            1\n",
    "                     \n",
    "          Where o is positive and * is negative\n",
    "\n",
    "\n",
    "If we were to attempt to draw a line to separate the positive answers from the negative answers, we would find that there is no point where a single line can be drawn to separate the answers. Because of this, XOR is not considered a linearly separable problem. Because XOR is not linearly separable, it is impossible to design a network with only one layer. This means we need at least one more layer to solve the XOR problem. The deep neural network solved in class is a network of 2 layers, which is the simplest network we can create to solve a non-linear problem. Therefore, we cannot simplify the network created in class any further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Boston Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Import boston housing into training and testing datasets\n",
    "from keras.datasets import boston_housing\n",
    "(train_images, train_labels), (test_images, test_labels) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "training images             \n",
      "\tcount: 404             \n",
      "\tdimensions: 2             \n",
      "\tshape: (404, 13)             \n",
      "\tdata type: float64\n",
      "\n",
      " testing images             \n",
      "\tcount: 102             \n",
      "\tdimensions: 1             \n",
      "\tshape: (102,)             \n",
      "\tdata type: float64             \n",
      "\tvalues: [ 7.2 18.8 19.  27.  22.2 24.5 31.2 22.9 20.5 23.2 18.6 14.5 17.8 50.\n",
      " 20.8 24.3 24.2 19.8 19.1 22.7 12.  10.2 20.  18.5 20.9 23.  27.5 30.1\n",
      "  9.5 22.  21.2 14.1 33.1 23.4 20.1  7.4 15.4 23.8 20.1 24.5 33.  28.4\n",
      " 14.1 46.7 32.5 29.6 28.4 19.8 20.2 25.  35.4 20.3  9.7 14.5 34.9 26.6\n",
      "  7.2 50.  32.4 21.6 29.8 13.1 27.5 21.2 23.1 21.9 13.  23.2  8.1  5.6\n",
      " 21.7 29.6 19.6  7.  26.4 18.9 20.9 28.1 35.4 10.2 24.3 43.1 17.6 15.4\n",
      " 16.2 27.1 21.4 21.5 22.4 25.  16.6 18.6 22.  42.8 35.1 21.5 36.  21.9\n",
      " 24.1 50.  26.7 25. ]\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Code pulled from numpy.ipynb to print dataset metrics\n",
    "print(\n",
    "        'training images \\\n",
    "            \\n\\tcount: {} \\\n",
    "            \\n\\tdimensions: {} \\\n",
    "            \\n\\tshape: {} \\\n",
    "            \\n\\tdata type: {}\\n\\n'.format(\n",
    "                len(train_images),\n",
    "                train_images.ndim,\n",
    "                train_images.shape,\n",
    "                train_images.dtype\n",
    "        ),\n",
    "        'testing images \\\n",
    "            \\n\\tcount: {} \\\n",
    "            \\n\\tdimensions: {} \\\n",
    "            \\n\\tshape: {} \\\n",
    "            \\n\\tdata type: {} \\\n",
    "            \\n\\tvalues: {}\\n'.format(\n",
    "                len(test_labels),\n",
    "                train_labels.ndim,\n",
    "                test_labels.shape,\n",
    "                test_labels.dtype,\n",
    "                test_labels\n",
    "        )\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Validation data length: 50\n",
      "Validation label length: 50\n",
      "\n",
      "New training data length: 354\n",
      "New training label length: 354\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Training data length\n",
    "t_length = len(train_images)\n",
    "\n",
    "# Take last 50 points of training data and make a validation set\n",
    "val_images = train_images[-50:]\n",
    "val_labels = train_labels[-50:]\n",
    "\n",
    "# Remove last 50 values from the training data\n",
    "train_images = train_images[:(t_length-50)]\n",
    "train_labels = train_labels[:(t_length-50)]\n",
    "\n",
    "print(\"Validation data length: \" + str(len(val_images)))\n",
    "print(\"Validation label length: \" + str(len(val_labels)))\n",
    "print(\"\\nNew training data length: \" + str(len(train_images)))\n",
    "print(\"New training label length: \" + str(len(train_labels)))\n",
    "\n",
    "# Note that the testing data has already been loaded from the import"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Create one new synthetic feature\n",
    "\n",
    "# Convert numpy dataset to pandas dataset\n",
    "training_images = pd.DataFrame(data=train_images, \n",
    "                               columns=[\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"])\n",
    "\n",
    "validation_images = pd.DataFrame(data=val_images, \n",
    "                               columns=[\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"])\n",
    "\n",
    "testing_images = pd.DataFrame(data=test_images, \n",
    "                               columns=[\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"])\n",
    "\n",
    "# Synthetic feature: Average number of rooms per dwellings built prior to 1940\n",
    "training_images[\"rooms_per_old_dwellings\"] = training_images[\"RM\"] * training_images[\"AGE\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This synthetic feature could be useful for machine learning because creating a\n",
    "model trained on this could potentially predict if a house was built before\n",
    "the 1940s based on the number of rooms present in the house. It makes sense\n",
    "statistically that older houses may contain less rooms on average than more\n",
    "modern houses. If this is the case, it is possible to train a machine learning\n",
    "model to predict the age of the house based on the number of total rooms\n",
    "present in the house."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}