Luke Steffen (lhs3)
CS-344: Artificial Intelligence
Lab 02 Answers

Exercise 2.1

	a. Both hill climbing and simulated annealing are able to solve the
	problem. Both solutions are also able to find the correct solution.

	b. Hill climbing is able to work more quickly than simulated
	annealing. This is beacuse once hill climbing has found the neighbor
	with the highest value, it stops running and returns the value it has
	found. Simulated annealing will sometimes accept a neighbor with a 
	worse value and runs based on a timer given to it.

	c. In this specific problem instance, the starting value for x will
	not matter. This is because this problem only has a global maxima,
	which is x = 15. This means that hill climbing will always find the
	true maxima. However, if there were multiple local maxima, the
	starting value for x would matter for hill climbing. Simulated
	annealing would have little to no issue with the starting x value.

	d. Changing the delta step value would make no difference on both
	algorithms, and the search algorithm will remain the same it has.
	However, it will change the final answer that results from both
	search algorithms. Changing the delta value will change how the
	graph steps up each value. The smaller the delta step, the
	smaller time until each node is value. A smaller delta step will
	create more values to evaluate, which will in turn make the
	algorithms take longer, but nothing about the algorithm is
	changed. A larger delta step will result in fewer nodes that
	will be valued.

	e. The exp_schedule() method acts as a sort of timer, simulating
	a "higher temperature." When this function is called, it will return
	a time value. This time value will be used in simulated annealing
	as a weight to help determine whether or not to accept the next
	choice, if it has a lower value than the current choice. The longer
	the timer has gone on, the less likely simulated annealing is to 
	pick the next choice if it has a lower value. This ensures that
	simulated annealing will not make any negative changes when the
	timer gets closer to running out of time.
	
Exercise 2.2

	a. Both of the problems typically are not able to find the best
	solution, but simulated annealing will typically perform better
	than hill climbing. Hill climbing will often not move or move
	very little because it is on or near a local maxima. Simulated
	annealing will often find a value that is better than the value
	that hill climbing was able to find, even though it is not the
	global maxima value.

	b. The starting value does make a difference to an extent with both
	of these algorithms. It makes the largest difference with hill
	climbing, because depending on where the initial value is, hill
	climbing may only find a local maxima value. The initial value will
	have less of an impact on the simulated annealing algorithm because
	it is able to break out of local maxima and randomly search for the
	global maxima. It is often able to find a value that is better than
	the solution hill climbing is able to find.

	c. Simulated annealing is better than hill climbing in this problem
	set. This is because simulated annealing will occasionally select a
	a next node that is of lesser value than its current value. By doing
	this, simulated annealing can prevent getting itself caught in local
	maxima unlike hill climbing. Simulated annealing has a far higher
	probability of finding the true global maxima because it can jump out
	of local maxima. As the timer counts down, simulated annealing will be
	far less likely to take a lesser value node, ensure the algorithm does
	not take a bad node at the end of the timer.

Exercise 2.3

	a. Each algorithm in general does better with restarts than it does
	without any of the restarts. This is because there is randomization
	added in to the hill climbing method which in turn helps it "get out"
	of local maxima by restarting the search at a different starting point.
	this gives the hill climbing algorithm a chance to search at a better
	starting point where it could find the global maxima. With simulated
	annealing, the random restarts adds a further element of randomization,
	which in turn helps simulted annealing run multiple times and find the
	best value. Statistically, running simulated annealing multiple times
	starting at multiple points will result in a higher chance of finding
	the best value.

	b. The average value for hill climbing is around 25 where the
	simulated annealing average value is around 37.

	c. Simulated annealing does better than hill climbing with random
	restarts. This is because the random restarts will help both hill
	climbing and simulated annealing, resulting in both algorithms
	getting better scores. However, since simulated annealing is already
	better than hill climbing for problems with many local maxima,
	simulated annealing will by default be better at finding the true
	global maxima than hill climbing.

Exercise 2.4

	a. Simulated annealing would be the best algorithm to implement a
	local beam search. This is because successor nodes are only accepted
	if that successor is better than the current node. Because simulated
	annealing has a better chance of finding a better node, simulated 
	annealing would be the better algorithm choice.

	b. With reasonalbe space and time constraints, you could maintain
	probably around 25 different solutions. Any more than that would
	most likely strain the system to a great amount and may take up too
	much time.

	c. To implement local beam search, I would modify the code to keep
	track of the path the best value from simulated annealing takes, as
	well as making the initial value go up sequentially. For example, if
	the current choice for best value is x: 7 value: 9, I would store that
	node in an array. If simulated annealing is run again with the next x and
	finds x: 8 value: 25, I would add that value onto the array and make
	that new result the best value. After the local beam search is done, I
	would print out this path to show the steps simulated annealing took to
	get the best value. This process is very similar to random restarts, with
	the differences being keeping track of the path to the best answer rather
	than just the best answer itself, as well as making the x value go up
	sequentially to x = 30 rather than randomly picking starting points. 
